{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from sinet import SINet_ResNet50\n",
    "from dataloader import get_loader\n",
    "from trainer import trainer, adjust_lr\n",
    "import torch.nn as nn\n",
    "# from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--epoch', type=int, default=40,\n",
    "                        help='epoch number, default=30')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                        help='init learning rate, try `lr=1e-4`')\n",
    "    parser.add_argument('--batchsize', type=int, default=36,\n",
    "                        help='training batch size (Note: ~500MB per img in GPU)')\n",
    "    parser.add_argument('--trainsize', type=int, default=352,\n",
    "                        help='the size of training image, try small resolutions for speed (like 256)')\n",
    "    parser.add_argument('--clip', type=float, default=0.5,\n",
    "                        help='gradient clipping margin')\n",
    "    parser.add_argument('--decay_rate', type=float, default=0.1,\n",
    "                        help='decay rate of learning rate per decay step')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=30,\n",
    "                        help='every N epochs decay lr')\n",
    "    parser.add_argument('--gpu', type=int, default=1,\n",
    "                        help='choose which gpu you use')\n",
    "    parser.add_argument('--save_epoch', type=int, default=10,\n",
    "                        help='every N epochs save your trained snapshot')\n",
    "    parser.add_argument('--save_model', type=str, default='./Snapshot/2020-CVPR-SINet/')\n",
    "    parser.add_argument('--train_img_dir', type=str, default='./Dataset/TrainDataset/Image/')\n",
    "    parser.add_argument('--train_gt_dir', type=str, default='./Dataset/TrainDataset/GT/')\n",
    "    opt = parser.parse_args()\n",
    "    opt.batchsize = 8\n",
    "    #torch.cuda.set_device(0)\n",
    "\n",
    "    # TIPS: you also can use deeper network for better performance like channel=64\n",
    "    model_SINet = SINet_ResNet50(channel=32).cuda()\n",
    "    print('-' * 30, model_SINet, '-' * 30)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_SINet.parameters(), opt.lr)\n",
    "    LogitsBCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    net = nn.DataParallel(model_SINet)\n",
    "\n",
    "    train_loader = get_loader(opt.train_img_dir, opt.train_gt_dir, batchsize=opt.batchsize,\n",
    "                              trainsize=opt.trainsize, num_workers=12)\n",
    "    total_step = len(train_loader)\n",
    "\n",
    "    print('-' * 30, \"\\n[Training Dataset INFO]\\nimg_dir: {}\\ngt_dir: {}\\nLearning Rate: {}\\nBatch Size: {}\\n\"\n",
    "                    \"Training Save: {}\\ntotal_num: {}\\n\".format(opt.train_img_dir, opt.train_gt_dir, opt.lr,\n",
    "                                                              opt.batchsize, opt.save_model, total_step), '-' * 30)\n",
    "\n",
    "    for epoch_iter in range(1, opt.epoch):\n",
    "        adjust_lr(optimizer, epoch_iter, opt.decay_rate, opt.decay_epoch)\n",
    "        trainer(train_loader=train_loader, model=model_SINet,\n",
    "                optimizer=optimizer, epoch=epoch_iter,\n",
    "                opt=opt, loss_func=LogitsBCE, total_step=total_step)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
